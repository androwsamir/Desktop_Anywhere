{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8700857,"sourceType":"datasetVersion","datasetId":5218424},{"sourceId":8701284,"sourceType":"datasetVersion","datasetId":5218627}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import WhisperForConditionalGeneration, WhisperTokenizer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom transformers import pipeline\nfrom collections import defaultdict\nfrom transformers import BertTokenizerFast\nfrom transformers import AutoModelForTokenClassification\nfrom transformers import WhisperFeatureExtractor\nimport torch\nimport os\nimport json","metadata":{"id":"m9tQPFw9pDe8","execution":{"iopub.status.busy":"2024-05-04T21:26:39.214265Z","iopub.execute_input":"2024-05-04T21:26:39.214695Z","iopub.status.idle":"2024-05-04T21:26:39.219952Z","shell.execute_reply.started":"2024-05-04T21:26:39.214599Z","shell.execute_reply":"2024-05-04T21:26:39.218948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whisperModel = WhisperForConditionalGeneration.from_pretrained(\"/kaggle/input/gp-voice-models/whisperModel/whisperModel\")\nwhisperTokenizer = WhisperTokenizer.from_pretrained(\"/kaggle/input/gp-voice-models/whisperModel/whisperModel\")\nwhisper_feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-medium\")\n\nclassification_path = '/kaggle/input/gp-voice-models/Classification_Model/Classification_Model/arabic-text-classification-model'\n\nNER_model_path = '/kaggle/input/gp-voice-models/NER_Model/NER_Model/Model'\nNER_tokenizer = '/kaggle/input/gp-voice-models/NER_Model/NER_Model/ModelTokenizer'\n\nclassificationTokenizer = AutoTokenizer.from_pretrained(classification_path)\nclassificationModel = AutoModelForSequenceClassification.from_pretrained(classification_path)\n\nNER_model = AutoModelForTokenClassification.from_pretrained(NER_model_path)\nNER_tokenizer = BertTokenizerFast.from_pretrained(NER_tokenizer)","metadata":{"id":"X5ef7VnwpHff","execution":{"iopub.status.busy":"2024-05-04T21:26:39.221633Z","iopub.execute_input":"2024-05-04T21:26:39.221886Z","iopub.status.idle":"2024-05-04T21:26:40.712658Z","shell.execute_reply.started":"2024-05-04T21:26:39.221865Z","shell.execute_reply":"2024-05-04T21:26:40.711878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def speechToText(voice_path):\n#         device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n#         torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n        pipe = pipeline(\n            \"automatic-speech-recognition\",\n            model=whisperModel,\n            tokenizer=whisperTokenizer,\n            feature_extractor=whisper_feature_extractor,\n            max_new_tokens=128,\n            chunk_length_s=30,\n            batch_size=16,\n            return_timestamps=True,\n#             torch_dtype=torch_dtype,\n#             device=device,\n        )\n        \n        # Update the sample to be an audio data\n        sample = open(f\"{voice_path}\", \"rb\").read()\n\n        result = pipe(sample, generate_kwargs={\"language\": \"arabic\"})\n\n        return result['text']","metadata":{"id":"s2ET4Xa2pQRQ","execution":{"iopub.status.busy":"2024-05-04T21:26:40.714091Z","iopub.execute_input":"2024-05-04T21:26:40.714431Z","iopub.status.idle":"2024-05-04T21:26:40.720641Z","shell.execute_reply.started":"2024-05-04T21:26:40.714405Z","shell.execute_reply":"2024-05-04T21:26:40.719691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def classify(text):\n    # Tokenize the input text and move tensors to the GPU if available\n    inputs = classificationTokenizer(text, padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n\n    # Get model output (logits)\n    outputs = classificationModel(**inputs)\n\n    probs = outputs[0].softmax(1)\n\n    pred_label_idx = probs.argmax()\n    pred_label = classificationModel.config.id2label[pred_label_idx.item()]\n\n    return pred_label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ner_entities(text):\n    nlp = pipeline(\"ner\", model=NER_model, tokenizer=NER_tokenizer)\n\n    ner_results = nlp(text)\n\n    # Extract entities and their corresponding labels\n    entities = defaultdict(list)\n    current_word = \"\"\n    current_labels = []\n    for result in ner_results:\n        # Handle subwords by concatenating them back into complete words\n        word = result['word']\n        if word.startswith('##'):\n            current_word += word[2:]\n        else:\n            if current_word:  # If there was a previous word, add it with its labels\n                entities[current_word].extend(current_labels)\n                current_word = \"\"  # Reset current_word for the next word\n                current_labels = []  # Reset current_labels for the next word\n            current_word = word\n            current_labels.append(result['entity'])\n\n    # Add the last word with its labels\n    if current_word:\n        entities[current_word].extend(current_labels)\n\n    # # Print entities and their labels\n    # for word, labels in entities.items():\n    #     # label = label_encoder.transform(labels)\n    #     print(f\"Word: {word}, Labels: {', '.join(labels)}\")\n    return entities","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"voice_path = \"/kaggle/input/gp-voices\"\nfile_names = os.listdir(voice_path)\nfor fileName in file_names:\n    output = speechToText(f'{voice_path}/{fileName}')\n    output = output.split('.')[0]\n    print(output)\n    className = classify(output)\n    print(f'class Name : {className}')\n    \n    entities = get_ner_entities(output)\n    with open(\"/kaggle/working/output.txt\", \"w\") as f:\n        f.write(className + \"\\n\")\n        for word, labels in entities.items():\n            print(f\"Word: {word}, Labels: {', '.join(labels)}\")\n            f.write(f\"Word: {word}, Labels: {', '.join(labels)}\" + \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-04T21:26:40.721996Z","iopub.execute_input":"2024-05-04T21:26:40.722394Z","iopub.status.idle":"2024-05-04T21:26:51.494344Z","shell.execute_reply.started":"2024-05-04T21:26:40.722362Z","shell.execute_reply":"2024-05-04T21:26:51.493462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}